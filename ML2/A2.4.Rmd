---
title: Advanced Topics in Machine Learning
subtitle: Sheet 2
author: Submitted by - Ranji Raj
date: "April 19th, 2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
header-includes:
- \usepackage{titling}
- \posttitle{\end{center}} \usepackage{fancyhdr} \pagestyle{fancy} 
---

# **Assignment 2.4 - Feature Scaling on KNN**

Dataset: _Pima Indian Diabetes_[^1]
```{r echo = FALSE, message=FALSE, warning=FALSE, out.width = '70%', fig.align="center"}
library(ggplot2)
library(gridExtra)
library(caret)
library(class) # For KNN
pima <- read.table("diabetes.csv", sep=",", header=TRUE)
pima$Outcome <- factor(pima$Outcome)
str(pima)
#hist(pima$Pregnancies, 100, col="black")
#qqnorm(pima$Pregnancies)
#my_cols <- c("#00AFBB", "#E7B800")  
#pairs(pima[,1:8], pch = 19, lower.panel = NULL, cex=0.5, col = my_cols[pima$Outcome],)
```
Training partition
```{r echo = FALSE, message=FALSE, warning=FALSE}
set.seed(1)
train.index <- createDataPartition(pima$Outcome, p = .7, list=FALSE)
train <- pima[ train.index,]
valid  <- pima[-train.index,]

summary(train$Outcome)
```
Validation partition
```{r echo = FALSE, message=FALSE, warning=FALSE}
summary(valid$Outcome)
```
__Performing 3-NN before Feature Scaling__
```{r echo = FALSE, message=FALSE, warning=FALSE}
train_feat <- train[,1:8] 
valid_feat <- valid[,1:8] 

set.seed(1)
train_pred <- knn(train_feat, train_feat, train$Outcome, k=3)
train_acc <- mean(train_pred == train$Outcome)

set.seed(1)
valid_pred <- knn(train_feat, valid_feat, train$Outcome, k=3)
valid_acc <- mean(valid_pred == valid$Outcome)

cat('Training Accuracy:   ', train_acc, '\n',
    'Validation Accuracy: ', valid_acc, sep='')
```

\newpage
__Min/Max Scaling__

On Training partition
```{r echo = FALSE, message=FALSE, warning=FALSE}
minmax_scaler <- preProcess(train_feat, method=c('range'))
train_mm_sc <- predict(minmax_scaler, train_feat)
valid_mm_sc <- predict(minmax_scaler, valid_feat)

summary(train_mm_sc)
```
On Validation partition
```{r echo = FALSE, message=FALSE, warning=FALSE}
summary(valid_mm_sc)
```
__Performing 3-NN on Min/Max scaled data__
```{r echo = FALSE, message=FALSE, warning=FALSE}
set.seed(1)
train_pred <- knn(train_mm_sc, train_mm_sc, train$Outcome, k=3)
train_acc <- mean(train_pred == train$Outcome)

set.seed(1)
valid_pred <- knn(train_mm_sc, valid_mm_sc, train$Outcome, k=3)
valid_acc <- mean(valid_pred == valid$Outcome)

cat('Training Accuracy:   ', train_acc, '\n',
    'Validation Accuracy: ', valid_acc, sep='')
```
```{r echo = FALSE, message=FALSE, warning=FALSE}
set.seed(1)

train_acc <- c()
valid_acc <- c()
train_acc_s_sc <- c()
valid_acc_s_sc <- c()
train_acc_mm_sc <- c()
valid_acc_mm_sc <- c()

k_range <- 1:100

for (i in k_range){
  # Unscaled
  set.seed(1)
  train_pred <- knn(train_feat, train_feat, train$Outcome, k=i)
  train_acc <- c(train_acc, mean(train_pred == train$Outcome))
  
  set.seed(1)
  valid_pred <- knn(train_feat, valid_feat, train$Outcome, k=i)
  valid_acc <- c(valid_acc, mean(valid_pred == valid$Outcome))
  
  # Standard Scaling
  # set.seed(1)
  # train_pred <- knn(train_s_sc, train_s_sc, train$Outcome, k=i)
  # train_acc_s_sc <- c(train_acc_s_sc, mean(train_pred == train$Outcome))
  # 
  # set.seed(1)
  # valid_pred <- knn(train_s_sc, valid_s_sc, train$Outcome, k=i)
  # valid_acc_s_sc <- c(valid_acc_s_sc, mean(valid_pred == valid$Outcome))
  
  # MinMax Scaling
  set.seed(1)
  train_pred <- knn(train_mm_sc, train_mm_sc, train$Outcome, k=i)
  train_acc_mm_sc <- c(train_acc_mm_sc, mean(train_pred == train$Outcome))
  
  set.seed(1)
  valid_pred <- knn(train_mm_sc, valid_mm_sc, train$Outcome, k=i)
  valid_acc_mm_sc <- c(valid_acc_mm_sc, mean(valid_pred == valid$Outcome))
  
}

#max(valid_acc)
```


```{r echo = FALSE, message=FALSE, warning=FALSE, out.width = '70%', fig.align="center"}

plot(k_range, train_acc, pch='.', ylim=c(0.65, 1), col='salmon', main = 'Learning curves for Unscaled data')
lines(k_range, train_acc, lwd=2, col='salmon')
lines(k_range, valid_acc, lwd=2, col='cornflowerblue')
legend(75, 1, legend=c("Training Acc", "Validation Acc"),
       col=c("salmon", "cornflowerblue"), lty=1, lwd=2, cex=0.8)
```
On unscaled data, the training accuracy is about __85%__ but the validation accuracy is about __71%__ and we check for possibilities to improve the accuracy on the latter.


```{r echo = FALSE, message=FALSE, warning=FALSE, out.width = '70%', fig.align="center"}
plot(k_range, train_acc_mm_sc, pch='.', ylim=c(0.65, 1), col='salmon', main = 'Learning curves for Min/Max scaled data')
lines(k_range, train_acc_mm_sc, lwd=2, col='salmon')
lines(k_range, valid_acc_mm_sc, lwd=2, col='cornflowerblue')
legend(75, 1, legend=c("Training Acc", "Validation Acc"),
       col=c("salmon", "cornflowerblue"), lty=1, lwd=2, cex=0.8)
```
Upon min/max scaling, the training accuracy is about around __85%__ but the validation accuracy is slightly better with __73%__. One discussion of not getting nearby accuracy as to training can be that the features chosen may not be appropriate.

\newpage
__Determing the Final model with optimal K=11__
```{r echo = FALSE, message=FALSE, warning=FALSE}
#which.max(valid_acc)
```

```{r echo = FALSE, message=FALSE, warning=FALSE}
set.seed(1)
train_pred <- knn(train, train, train$Outcome, k=11)
train_acc <- mean(train_pred == train$Outcome)
  
set.seed(1)
valid_pred <- knn(train, valid, train$Outcome, k=11)
valid_acc <- mean(valid_pred == valid$Outcome)

cat('Training Accuracy:   ', train_acc, '\n',
    'Validation Accuracy: ', valid_acc, sep='')
```

__Confusion Matrix__
```{r echo = FALSE, message=FALSE, warning=FALSE}
table(valid$Outcome, valid_pred)
```
The above Confusion Matrix is an indicative that with the optimal value of `K=11` we have the `FP=16` and `FN=33` which is desirable.

__Model Evaluation__
```{r echo = FALSE, message=FALSE, warning=FALSE}
confusionMatrix(valid_pred, valid$Outcome)
```
[^1]: https://www.kaggle.com/uciml/pima-indians-diabetes-database