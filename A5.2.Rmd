---
title: Advanced Topics in Machine Learning
subtitle: Sheet 5
author: Submitted by - Ranji Raj
date: "May 15, 2021"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{titling}
- \posttitle{\end{center}} \usepackage{fancyhdr} \pagestyle{fancy} 
---
# **Assignment 5.2 - Dual representation**


```{r echo=FALSE, message=FALSE, warning=FALSE, out.width = '70%', fig.align="center", results='hide'}
library(fontawesome)
```

### Dual representation

If _G_ is a group (binary operation) and $\rho$, is a linear representation of G, on the vector space _V_, then the __dual representation__ $\rho^*$ is defined over the dual vector space $V^*$ as follows:

$\rho^*(g)$ is the transpose of $\rho(g^{-1})$, i.e. $\rho^*(g)=\rho(g^{-1})^T$ for all $g \in G$.

- Simply invert each matrix and then take their transposes.


### Benefits

That the model can be learned using the training algorithm purely based on the input data $x_i$.

### Decision function of LLM in Dual representation

- Rewrite the basic function:
  - $f(x) = <w,x> + b = \sum_{i} \alpha_i y_i<x_i,x> + b$
  - with, $w=\sum_{i} \alpha_i y_i x_i$

- Change the update rule as:
  - IF $y_j \big (\sum_{i} \alpha_i y_i<x_i,x_j> + b\big) \le 0$
  - THEN $\alpha_j  \gets \alpha_j + \eta$

- Observation: __Data appears only inside inner dot products which the learner now needs as form of information__.















[`r fa("github", fill = "black")`](https://github.com/ranjiGT/ATiML-amendments)